causal dependency tracking
==============================
Each replica uses causal dependency list. The list contains value, version, and corresponding causal metadata of the request. The list is then stored in dictionary[key]. Each version have unique value, and that unique value is generated by incrementing the previous value -- initial value is 1. e.g if causal metadata is 1,2, it generates version 3, and returns version: "3", causal-metadata:"1,2,3". To keep track of what operations are done by the replica, a list called versionlist appends version of each request. So if causal-metadata is "1,2,3", the versionlist will look like [1,2,3]. If versionlist is not equal to causal-metadata, it queues that request until all previous operations are done. Note: GET request doesn't alter versionlist. 



Detecting a downed replica
--------------------------
Each replica maintains a list of sockets (called REPLICAS) that are currently online. Whenever a view operation requires the current state of the system, such as returning the current view or broadcasting a put operation, a function called getView is called. Every replica has an endpoint /ping/, which simply returns a 200 status code when called. 

To ensure that no dead replica is in the REPLICAS list, getView sends a GET request to the /ping/ endpoint of every replica in its list. If a replica fails to respond with a 200 status code within 10 seconds, it is declared dead and removed from the list. The current replica will then broadcast a DELETE request to all other replicas in its list, instructing them to remove the replica. After this operation completes, all remaining replicas in REPLICAS should be live nodes.

If a new replica is added to the system, the replica will run a function called onStart. This function will scan through each replica in its REPLICAS list and attempt to ping each replica. If a replica responds to the ping with 200 status code, the replica ceases the scan and sends a PUT request to the /key-value-store-view/ endpoint on that node. This instructs the receiving node to add the new node to its view and broadcast the addition to all known replicas in the receiving node's list. After this operation terminates, every replica should have added the new node to thier view.